version: '3.9'

services:

#########################################################
# Grafana
#########################################################

  grafana: # Running
  # logger=provisioning t=2024-10-03T11:48:05.043988869Z level=error msg="Failed to provision data sources" error="Datasource provisioning error: attempt to write a readonly database"
  # Error: âœ— Datasource provisioning error: attempt to write a readonly database
    image: grafana/grafana-enterprise:latest-ubuntu
    container_name: grafana
    hostname: grafana
    volumes:
      - ./grafana/data:/var/lib/grafana:rw
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:rw
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:rw
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=${ALLOW_SIGN_UP}
      - GF_INSTALL_IMAGE_RENDERER_PLUGIN=true
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    restart: unless-stopped
    ports:
      - 3000:3000
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

#########################################################
# Prometheus
#########################################################

  prometheus: # Running
  # ts=2024-10-03T11:51:04.379Z caller=main.go:549 level=error msg="Error loading config (--config.file=/etc/prometheus/prometheus.yml)" file=/etc/prometheus/prometheus.yml err="parsing YAML file /etc/prometheus/prometheus.yml: yaml: unmarshal errors:\n  line 10: field external_labels already set in type config.plain"
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: prometheus
    volumes:
      - ./prometheus:/etc/prometheus:rw
      - ./prometheus_data:/prometheus:rw
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=200h"
      - "--web.enable-lifecycle"
    depends_on:
      - "mimir-1"
      - "mimir-2"
      - "mimir-3"
    restart: unless-stopped
    ports:
      - 9090:9000
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

########################################################
# Mimir
#########################################################

  mimir-1: # Running
    image: grafana/mimir:latest
    container_name: mimir-1
    hostname: mimir-1
    command: 
      - "-config.file=/etc/mimir.yaml"
      - "-config.expand-env=true"
    ports:
      - 8080
    depends_on:
      - minio
    volumes:
      - ./mimir/config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - ./mimir/mimir.yaml:/etc/mimir.yaml:ro
      - mimir-1-data:/data
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

  mimir-2: # Running
    image: grafana/mimir:latest
    container_name: mimir-2
    hostname: mimir-2
    command: 
      - "-config.file=/etc/mimir.yaml"
      - "-config.expand-env=true"
    ports:
      - 8080
    depends_on:
      - minio
    volumes:
      - ./mimir/config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - ./mimir/mimir.yaml:/etc/mimir.yaml:ro
      - mimir-2-data:/data
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

  mimir-3: # Running
    image: grafana/mimir:latest
    container_name: mimir-3
    hostname: mimir-3
    command: 
      - "-config.file=/etc/mimir.yaml"
      - "-config.expand-env=true"
    ports:
      - 8080
    depends_on:
      - minio
    volumes:
      - ./mimir/config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - ./mimir/mimir.yaml:/etc/mimir.yaml:ro
      - mimir-3-data:/data
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

#########################################################
# Loki
#########################################################

  read: # Healthy
    image: grafana/loki:latest
    container_name: read
    hostname: read
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/config.yaml:rw
    command: 
      - "-config.file=/etc/loki/config.yaml"
      - "-config.expand-env=true"
      - "-target=read"
    depends_on:
      - minio
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    labels:
      org.label-schema.group: "monitoring"
    networks: &monitor-net-dns
      monitor-net:
        aliases:
          - monitor-net

  write: # Healthy
    container_name: write
    hostname: write
    image: grafana/loki:latest
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/config.yaml:rw
    command: 
      - "-config.file=/etc/loki/config.yaml"
      - "-config.expand-env=true"
      - "-target=write"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio
    labels:
      org.label-schema.group: "monitoring"
    networks:
      <<: *monitor-net-dns

  backend: # Running
  # level=error ts=2024-10-03T11:48:46.643652266Z caller=ruler.go:571 msg="unable to list rules" err="NoCredentialProviders: no valid providers in chain. Deprecated.\n\tFor verbose messaging see aws.Config.CredentialsChainVerboseErrors"
    image: grafana/loki:latest
    container_name: backend
    hostname: backend
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/config.yaml:rw
    ports:
      - "3100"
      - "7946"
    command: 
      - "-config.file=/etc/loki/config.yaml"
      - "-config.expand-env=true"
      - "-legacy-read-mode=false"
      - "-target=backend"
    depends_on:
      - gateway
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

#########################################################
# Databases
#########################################################

  influxdb: # Running
    image: influxdb:latest
    container_name: influxdb
    hostname: influxdb
    restart: always
    environment:
      - INFLUXDB_DB=influx
      - INFLUXDB_ADMIN_USER=${INFLUX_ADMIN_USER}
      - INFLUXDB_ADMIN_PASSWORD=${INFLUX_ADMIN_PASSWORD}
    ports:
      - '8086:8086'
    volumes:
      - ./influxdb/data:/var/lib/influxdb
      - ./influxdb:/etc/influxdb
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

#########################################################
# Collectors
#########################################################

  nodeexporter: # Running
    image: prom/node-exporter:latest
    container_name: nodeexporter
    hostname: nodeexporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.rootfs=/rootfs"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    restart: unless-stopped
    ports:
      - 9100:9100
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

  cadvisor: # Healthy
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    hostname: cadvisor
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /cgroup:/cgroup:ro #doesn't work on MacOS only for Linux
    restart: unless-stopped
    ports:
      - 8081:8080
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

  alloy: # Running
  # ts=2024-10-03T11:46:04.711649188Z level=warn msg="error sending batch, will retry" component_path=/ component_id=loki.write.default component=client host=gateway:3100 status=-1 tenant=tenant1 error="Post \"http://gateway:3100/loki/api/v1/push\": dial tcp: lookup gateway on 127.0.0.11:53: server misbehaving"
    image: grafana/alloy:latest
    container_name: alloy
    hostname: alloy
    volumes:
      - ./alloy/alloy-local-config.yaml:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock
    # user:
    #   "root:root"
    command:  "run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy"
    ports:
      - 12345:12345
    depends_on:
      - gateway
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

#########################################################
# Storage
#########################################################

  minio: # Healthy
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    entrypoint: [""]
    command:
      - "sh"
      - "-euc"
      - "mkdir -p /data/loki-data && mkdir -p /data/loki-ruler && mkdir -p /data/mimir && minio server --quiet /data"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_PROMETHEUS_AUTH_TYPE=${MINIO_PROMETHEUS_AUTH_TYPE}
      - MINIO_UPDATE=off
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

#########################################################
# Proxies and Gateways
#########################################################

  load-balancer:
    image: nginx:latest
    container_name: loadbalancer
    hostname: loadbalancer
    volumes:
      - ./loadbalancer/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - "mimir-1"
      - "mimir-2"
      - "mimir-3"
    ports:
      - 9009:9009

  gateway:
    image: nginx:latest
    container_name: gateway
    hostname: gateway
    volumes:
      - ./gateway/nginx.conf:/etc/nginx/nginx.conf:rw
    depends_on:
      - read
      - write
    entrypoint:
      - 'sh'
      - '-eu'
      - '-c /docker-entrypoint.sh nginx -g \"daemon off\";'
    ports:
      - 3100:3100
    healthcheck:
      test: ["CMD", "service", "nginx", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

  pushgateway: # Running
    image: prom/pushgateway:latest
    container_name: pushgateway
    hostname: pushgateway
    restart: unless-stopped
    ports:
      - 9091:9091
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

########################################################
# Alerts
#########################################################

  alertmanager: # Running
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./alertmanager/config.yml:/etc/alertmanager/config.yml
      - ./prometheus/config:/etc/prometheus
      - ./prometheus/data:/prometheus
    command:
      - "--config.file=/etc/alertmanager/config.yml"
      - "--storage.path=/alertmanager"
    restart: unless-stopped
    ports:
      - 9093:9093
    labels:
      org.label-schema.group: "monitoring"
    networks:
      - monitor-net

########################################################
# Network
#########################################################

networks:
  monitor-net:
    driver: bridge

########################################################
# Volumes
#########################################################

volumes:
  mimir-1-data:
  mimir-2-data:
  mimir-3-data:
  minio-data:
